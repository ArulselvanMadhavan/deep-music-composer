{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano import function\n",
    "import cPickle as pickle\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO \n",
    "1. Changed the categorical cross entropy to binary cross entropy\n",
    "2. Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class layer_rnn:\n",
    "    def __init__(self, n_steps, input_dim, output_dim, hidden_dim, preload_model=None):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_steps = np.float32(n_steps)\n",
    "        self.preload_model = preload_model\n",
    "        self.test_acc = None\n",
    "        self.conf_matrix = None\n",
    "        np.random.seed(12345)\n",
    "        if preload_model is None:\n",
    "            #Wxh\n",
    "            U = np.random.uniform(-np.sqrt(1./input_dim), np.sqrt(1./input_dim), (input_dim, hidden_dim))\n",
    "            #Why\n",
    "            V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, output_dim))\n",
    "            #Whh\n",
    "            W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))\n",
    "        else:\n",
    "            U,V,W = self.load_model()\n",
    "        self.U = theano.shared(name=\"U\", value=U.astype(\"f\"))\n",
    "        self.V = theano.shared(name=\"V\", value=V.astype(\"f\"))\n",
    "        self.W = theano.shared(name=\"W\", value=W.astype(\"f\"))\n",
    "        \n",
    "        self.define_network()\n",
    "    \n",
    "    def step(self, x_t, s_t_prev, act=T.nnet.softmax):\n",
    "        s_t = T.tanh(T.dot(x_t, self.U) + T.dot(s_t_prev, self.W))\n",
    "        o_t = act(T.dot(s_t, self.V))\n",
    "        return o_t, s_t\n",
    "    \n",
    "    def define_network(self):\n",
    "        U, V, W = self.U, self.V, self.W\n",
    "        x = T.ftensor3(\"input\")\n",
    "        onehot_y = T.fmatrix(\"onehot_labels\")\n",
    "        step_idx = 0\n",
    "        \n",
    "        sum_states = T.zeros((x.shape[0], self.output_dim), dtype=\"f\")\n",
    "        states = T.zeros((x.shape[0], self.hidden_dim), dtype=\"f\")\n",
    "        for step_idx in range(0, self.n_steps):\n",
    "            o_t, states = self.step(x[:, step_idx, :], states)\n",
    "            sum_states += o_t\n",
    "        mean_states = sum_states/self.n_steps\n",
    "        \n",
    "        prediction = T.argmax(mean_states, axis=1)\n",
    "        accuracy = T.mean(T.eq(T.argmax(mean_states, axis=1), T.argmax(onehot_y, axis=1)))\n",
    "        to_label = T.argmax(onehot_y, axis=1)\n",
    "        cost = T.mean(T.nnet.categorical_crossentropy(mean_states, onehot_y))\n",
    "        \n",
    "        self.get_accuracy = function([x, onehot_y, states], accuracy, on_unused_input='warn')\n",
    "        self.get_cost = function([x, onehot_y, states], cost, on_unused_input=\"warn\")\n",
    "        self.get_prediction = function([x], prediction)\n",
    "        self.from_onehot_to_label = function([onehot_y], to_label)\n",
    "        \n",
    "        #Gradients\n",
    "        dU = T.grad(cost, U)\n",
    "        dV = T.grad(cost, V)\n",
    "        dW = T.grad(cost, W)\n",
    "        \n",
    "        learning_rate = T.scalar(\"learning_rate\", dtype=\"float32\")\n",
    "        self.sgd_step = theano.function([x, onehot_y, learning_rate],[cost], updates=[\n",
    "                (U, U - learning_rate*dU),\n",
    "                (V, V - learning_rate*dV),\n",
    "                (W, W - learning_rate*dW)])\n",
    "        self.states = states\n",
    "        self.sum_states = sum_states\n",
    "    \n",
    "    def train(self, X, Y, mini_batch, learning_rate, num_epochs, \n",
    "              evaluation_log=\"train.log\", dump_model_name=None,Xv=[],Yv=[],Xt=[],Yt=[]):\n",
    "        n_train = X.shape[0]\n",
    "        n_batch = np.int(n_train/mini_batch)\n",
    "        tr_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = None\n",
    "        tr_loss = []\n",
    "        for epoch_idx in range(num_epochs):\n",
    "            perm = np.random.permutation(len(X))\n",
    "            X = X[perm]\n",
    "            Y = Y[perm]\n",
    "            for batch_idx in range(n_batch):\n",
    "                start = batch_idx * mini_batch\n",
    "                end = min(start + mini_batch, n_train)\n",
    "                self.sgd_step(X[start:end], Y[start:end], learning_rate)\n",
    "            tr_loss.append(self.calc_loss(X, Y).item(0))\n",
    "            tr_acc.append(self.calc_accuracy(X, Y).item(0))\n",
    "            print(\"Epoch:{}\\tLoss:{}\".format(epoch_idx, tr_loss[-1]))\n",
    "            if len(Xv) > 0:\n",
    "                val_acc.append(self.calc_accuracy(Xv, Yv).item(0))\n",
    "                print('Train_Acc:{}\\tVal_acc:{})'.format(tr_acc[-1], val_acc[-1]))\n",
    "        \n",
    "        if len(Xt) > 0:\n",
    "            self.test_acc = self.calc_accuracy(Xt, Yt).item(0)\n",
    "            print(\"Test accuracy:{}\".format(self.test_acc))\n",
    "            pred_test_y = self.get_prediction(Xt)\n",
    "            self.conf_matrix = confusion_matrix(self.from_onehot_to_label(Yt), pred_test_y)\n",
    "        \n",
    "        self.tr_acc = tr_acc\n",
    "        self.val_acc = val_acc\n",
    "        self.dump_model(dump_model_name)\n",
    "        self.dump_training_log(evaluation_log)\n",
    "        \n",
    "        print(\"Finished Training. Model dumped in {}\".format(dump_model_name))\n",
    "        print(\"Training log dumped in {}\".format(evaluation_log))\n",
    "    \n",
    "    def calc_accuracy(self, X, Y):\n",
    "        return self.get_accuracy(X, Y, np.zeros((len(X), self.hidden_dim), dtype=\"f\"))\n",
    "    \n",
    "    def calc_loss(self, X, Y):\n",
    "        return self.get_cost(X, Y, np.zeros((len(X), self.hidden_dim), dtype=\"f\"))\n",
    "    \n",
    "    def dump_training_log(self, filename):\n",
    "        with open(filename, 'wb') as outfile:\n",
    "            if len(self.tr_acc) > 0:\n",
    "                pickle.dump(self.tr_acc, outfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            if len(self.val_acc) > 0:\n",
    "                pickle.dump(self.val_acc, outfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            if self.test_acc is not None:\n",
    "                pickle.dump(self.test_acc, outfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            if self.conf_matrix is not None:\n",
    "                pickle.dump(self.conf_matrix, outfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def dump_model(self, filename):\n",
    "        with open(filename, 'wb') as outfile:\n",
    "            pickle.dump(self.U.get_value(), outfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            pickle.dump(self.V.get_value(), outfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            pickle.dump(self.W.get_value(), outfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def load_model(self):\n",
    "        with open(self.preload_model, 'rb') as infile:\n",
    "            U = pickle.load(infile)\n",
    "            assert(U.shape[0] == self.input_dim and U.shape[1] == self.hidden_dim)\n",
    "            V = pickle.load(infile)\n",
    "            assert(V.shape[0] == self.hidden_dim and V.shape[1] == self.output_dim)\n",
    "            W = pickle.load(infile)\n",
    "            assert(W.shape[0] == self.hidden_dim and W.shape[1] == self.hidden_dim)\n",
    "            return U, V, W\n",
    "    \n",
    "    def viz_U(self, row_indices):\n",
    "        U = self.U.get_value()\n",
    "        n_rows = len(row_indices)\n",
    "        fig = plt.figure()\n",
    "        for i, row in enumerate(row_indices, 1):\n",
    "            a = fig.add_subplot(n_rows, 1, i)\n",
    "            a.set_title('row %d in U' % row)\n",
    "            a.set_yticks([])\n",
    "            U_row = U[:, row].reshape(1, U.shape[0])\n",
    "            U_row = (U_row - np.min(U_row)) / (np.max(U_row) - np.min(U_row))\n",
    "            plt.imshow(U_row, cmap='gray', interpolation='nearest')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('viz_U.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from data_handler import load_data, onehot\n",
    "import numpy as np\n",
    "import theano\n",
    "from util import load_training_log, plot_confusion_matrix\n",
    "\n",
    "theano.config.floatX = 'float32'\n",
    "theano.config.exception_verbosity = 'high'\n",
    "\n",
    "params = []\n",
    "\n",
    "# Read MNIST training set, validation set, and test set\n",
    "(X, Y), (Xv, Yv), (Xt, Yt) = load_data('mnist.pkl.gz')\n",
    "Y = onehot(Y)\n",
    "Yv = onehot(Yv)\n",
    "Yt = onehot(Yt)\n",
    "\n",
    "input_dim = X.shape[2]\n",
    "output_dim = Y.shape[1]\n",
    "hidden_dim = 200\n",
    "mini_batch = 100\n",
    "num_epochs = 100\n",
    "lr = np.float32(0.01)\n",
    "n_steps = X.shape[1]\n",
    "\n",
    "# define theano network\n",
    "rnn = layer_rnn(n_steps=n_steps,\n",
    "                input_dim=X.shape[2], output_dim=Y.shape[1],\n",
    "                hidden_dim=hidden_dim)\n",
    "\n",
    "rnn.train(X, Y, mini_batch=mini_batch, learning_rate=lr, num_epochs=num_epochs,\n",
    "            dump_model_name='rnn.model', Xv=Xv, Yv=Yv, Xt=Xt, Yt=Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((8704, 128, 12), (8704, 24))\n"
     ]
    }
   ],
   "source": [
    "X = np.load(\"../../train_input_128_int32.npy\")\n",
    "Y = np.load(\"../../train_target_128_int32.npy\")\n",
    "X = X.astype(np.float32)\n",
    "Y = Y.astype(np.float32)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\tLoss:1.44560360909\n",
      "Epoch:1\tLoss:1.4207098484\n",
      "Epoch:2\tLoss:1.38999915123\n",
      "Epoch:3\tLoss:1.34529662132\n",
      "Epoch:4\tLoss:1.26035785675\n",
      "Epoch:5\tLoss:1.21140086651\n",
      "Epoch:6\tLoss:1.19641709328\n",
      "Epoch:7\tLoss:1.18950366974\n",
      "Epoch:8\tLoss:1.18510937691\n",
      "Epoch:9\tLoss:1.18184173107\n",
      "Epoch:10\tLoss:1.1793115139\n",
      "Epoch:11\tLoss:1.17718434334\n",
      "Epoch:12\tLoss:1.17545425892\n",
      "Epoch:13\tLoss:1.17351567745\n",
      "Epoch:14\tLoss:1.17184734344\n",
      "Epoch:15\tLoss:1.17022073269\n",
      "Epoch:16\tLoss:1.16840004921\n",
      "Epoch:17\tLoss:1.16667103767\n",
      "Epoch:18\tLoss:1.16479432583\n",
      "Epoch:19\tLoss:1.16287446022\n",
      "Epoch:20\tLoss:1.16089355946\n",
      "Epoch:21\tLoss:1.15896916389\n",
      "Epoch:22\tLoss:1.15649724007\n",
      "Epoch:23\tLoss:1.15417468548\n",
      "Epoch:24\tLoss:1.15162622929\n",
      "Epoch:25\tLoss:1.14891862869\n",
      "Epoch:26\tLoss:1.14583647251\n",
      "Epoch:27\tLoss:1.14273035526\n",
      "Epoch:28\tLoss:1.13938331604\n",
      "Epoch:29\tLoss:1.1359089613\n",
      "Epoch:30\tLoss:1.13248312473\n",
      "Epoch:31\tLoss:1.12846362591\n",
      "Epoch:32\tLoss:1.12505030632\n",
      "Epoch:33\tLoss:1.12149059772\n",
      "Epoch:34\tLoss:1.11919689178\n",
      "Epoch:35\tLoss:1.11651861668\n",
      "Epoch:36\tLoss:1.11393630505\n",
      "Epoch:37\tLoss:1.11191129684\n",
      "Epoch:38\tLoss:1.10869622231\n",
      "Epoch:39\tLoss:1.10715138912\n",
      "Epoch:40\tLoss:1.10826635361\n",
      "Epoch:41\tLoss:1.10809195042\n",
      "Epoch:42\tLoss:1.10433113575\n",
      "Epoch:43\tLoss:1.1068187952\n",
      "Epoch:44\tLoss:1.10316705704\n",
      "Epoch:45\tLoss:1.10160911083\n",
      "Epoch:46\tLoss:1.10507571697\n",
      "Epoch:47\tLoss:1.10895347595\n",
      "Epoch:48\tLoss:1.09926509857\n",
      "Epoch:49\tLoss:1.10475826263\n",
      "Epoch:50\tLoss:1.10173213482\n",
      "Epoch:51\tLoss:1.09991466999\n",
      "Epoch:52\tLoss:1.10053753853\n",
      "Epoch:53\tLoss:1.1002304554\n",
      "Epoch:54\tLoss:1.09619772434\n",
      "Epoch:55\tLoss:1.09661698341\n",
      "Epoch:56\tLoss:1.09437477589\n",
      "Epoch:57\tLoss:1.09425973892\n",
      "Epoch:58\tLoss:1.09282505512\n",
      "Epoch:59\tLoss:1.09239864349\n",
      "Epoch:60\tLoss:1.09275317192\n",
      "Epoch:61\tLoss:1.09207475185\n",
      "Epoch:62\tLoss:1.09027528763\n",
      "Epoch:63\tLoss:1.09401476383\n",
      "Epoch:64\tLoss:1.08815228939\n",
      "Epoch:65\tLoss:1.08673262596\n",
      "Epoch:66\tLoss:1.12770223618\n",
      "Epoch:67\tLoss:1.09657382965\n",
      "Epoch:68\tLoss:1.09365034103\n",
      "Epoch:69\tLoss:1.09271454811\n",
      "Epoch:70\tLoss:1.09054040909\n",
      "Epoch:71\tLoss:1.0922601223\n",
      "Epoch:72\tLoss:1.08912670612\n",
      "Epoch:73\tLoss:1.08720839024\n",
      "Epoch:74\tLoss:1.08459627628\n",
      "Epoch:75\tLoss:1.08361983299\n",
      "Epoch:76\tLoss:1.08149790764\n",
      "Epoch:77\tLoss:1.07835996151\n",
      "Epoch:78\tLoss:1.08043670654\n",
      "Epoch:79\tLoss:1.08410203457\n",
      "Epoch:80\tLoss:1.07953369617\n",
      "Epoch:81\tLoss:1.07516992092\n",
      "Epoch:82\tLoss:1.17484688759\n",
      "Epoch:83\tLoss:1.07564926147\n",
      "Epoch:84\tLoss:1.07259249687\n",
      "Epoch:85\tLoss:1.14107882977\n",
      "Epoch:86\tLoss:1.07488834858\n",
      "Epoch:87\tLoss:1.07149684429\n",
      "Epoch:88\tLoss:1.07010507584\n",
      "Epoch:89\tLoss:1.06766533852\n",
      "Epoch:90\tLoss:1.07264614105\n",
      "Epoch:91\tLoss:1.27803397179\n",
      "Epoch:92\tLoss:1.09018957615\n",
      "Epoch:93\tLoss:1.07970666885\n",
      "Epoch:94\tLoss:1.07181239128\n",
      "Epoch:95\tLoss:1.18397760391\n",
      "Epoch:96\tLoss:1.12869942188\n",
      "Epoch:97\tLoss:1.12407052517\n",
      "Epoch:98\tLoss:1.31622409821\n",
      "Epoch:99\tLoss:1.19147264957\n",
      "Finished Training. Model dumped in rnn.model\n",
      "Training log dumped in train.log\n"
     ]
    }
   ],
   "source": [
    "theano.config.floatX = 'float32'\n",
    "theano.config.exception_verbosity = 'high'\n",
    "\n",
    "params = []\n",
    "\n",
    "input_dim = X.shape[2]\n",
    "output_dim = Y.shape[1]\n",
    "hidden_dim = 200\n",
    "mini_batch = 128\n",
    "num_epochs = 100\n",
    "lr = np.float32(0.01)\n",
    "n_steps = X.shape[1]\n",
    "\n",
    "# define theano network\n",
    "rnn = layer_rnn(n_steps=n_steps,\n",
    "                input_dim=X.shape[2], output_dim=Y.shape[1],\n",
    "                hidden_dim=hidden_dim)\n",
    "\n",
    "rnn.train(X, Y, mini_batch=mini_batch, learning_rate=lr, num_epochs=num_epochs,\n",
    "            dump_model_name='rnn.model', Xv=[], Yv=[], Xt=[], Yt=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
